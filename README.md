# ğŸ“„ Chat with Your Document (RAG + LangChain)

This project enables users to **upload a document and chat with it** using a **Retrieval-Augmented Generation (RAG) pipeline**. It leverages:

- **FAISS** for vector storage  
- **Ollama (DeepSeek-R1:1.5B)** for LLM-based question answering  
- **LangChain** for integrating embeddings and retrieval  
- **Streamlit** for an interactive UI  

---

## **ğŸ› ï¸ Setup Guide**

### **1ï¸âƒ£ Install Prerequisites**

Ensure you have **Python 3.10+** installed. Then, install **Miniconda** (if not already installed):

ğŸ‘‰ **Mac/Linux:**  
```bash
brew install miniforge
```

ğŸ‘‰ **Windows:**  
Download and install [Miniconda](https://docs.conda.io/en/latest/miniconda.html).

---

### **2ï¸âƒ£ Create and Activate a Conda Environment**
```bash
conda create -n doc-rag
conda activate doc-rag
```

---

### **3ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/your-username/doc-rag.git
cd doc-rag
```

---

### **4ï¸âƒ£ Install Required Packages**
```bash
pip install -r requirements.txt
```

ğŸ“Œ **Ensure Ollama is installed:**  
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

---

### **5ï¸âƒ£ Set Up Environment Variables**

Create a `.env` file in the root directory and add:

```ini
# API Keys (if using cloud embeddings)
JINA_API_KEY="your_jina_api_key"

# Ollama Model
OLLAMA_MODEL="deepseek-r1:7b"

# Vector Store Path
VECTOR_DB_PATH="faiss_index"
```

---

### **6ï¸âƒ£ Download the Ollama Model**
Before running the app, pull the **DeepSeek model**:
```bash
ollama pull deepseek-r1:1.5b
```

---

### **7ï¸âƒ£ Run the Streamlit App**
```bash
streamlit run app.py
```

---

## **ğŸ–¥ï¸ How It Works**

### **ğŸ“¤ Upload a Document**
1. Launch the Streamlit app.  
2. Upload a **PDF document** via the file uploader.  

### **ğŸ§  Processing**
- The app **extracts text** from the document.  
- Text is **converted into embeddings** using a **local embedding model** (or Jina).  
- Embeddings are stored in a **FAISS vector database**.  

### **ğŸ’¬ Ask Questions**
- Type a question in the chat box.  
- The system retrieves relevant document sections and generates a response using **DeepSeek**.  

---

## **ğŸ› ï¸ Troubleshooting**

### **ğŸ”´ Conda Environment Not Found**
**Error:**  
```
conda: command not found
```
âœ… **Solution:**  
Install Miniconda and restart your terminal.

---

### **ğŸ”´ Ollama Model Not Found**
**Error:**  
```
ValueError: model "deepseek" not found, try pulling it first
```
âœ… **Solution:**  
Run:
```bash
ollama pull deepseek-r1:1.5b
```

---

### **ğŸ”´ FAISS Index Not Found**
**Error:**  
```
FileNotFoundError: No FAISS index found
```
âœ… **Solution:**  
Re-upload a document to **rebuild the FAISS index**.

---

### **ğŸ”´ Streamlit Not Found**
**Error:**  
```
streamlit: command not found
```
âœ… **Solution:**  
Activate your virtual environment:
```bash
conda activate doc-rag
```
Then reinstall Streamlit:
```bash
pip install streamlit
```

---

## **ğŸ¯ Future Enhancements**
- **Multi-document support**  
- **Improved UI with chatbot memory**  
- **Integration with GPT-4 or Claude for better responses**  

---

ğŸ‰ **Youâ€™re all set!** Start chatting with your documents now. ğŸš€

